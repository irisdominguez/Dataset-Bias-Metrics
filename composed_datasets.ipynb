{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74749972-6d21-4fb7-9ed2-8767c5c25f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66322c37-16ad-473e-850e-1c7e30143cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec1a56-b07a-4014-b590-e6cbfa60dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "setMatPlotLib(style='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70950c71-f82e-47e1-9b08-46e1a1327857",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57496b2-3112-4262-a6b8-60817c65c38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b375a06-a628-491f-a6d7-95193a6074e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789fa0e-d17b-441a-b052-7020ca9f33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateComposedDataset(ds_names, target, target_names, balance, vocab=base_vocab):\n",
    "    final_ds = []\n",
    "\n",
    "    for partition in ['train', 'val']:\n",
    "        for name in ds_names:\n",
    "            ds = FERDataset2(name, vocab=vocab, load=False)\n",
    "            \n",
    "            ds_agg = ds.df\n",
    "            ds_agg = ds_agg[ds_agg['partition'] == partition]\n",
    "            ds_agg = ds_agg[ds_agg[target].isin(target_names)]\n",
    "            \n",
    "            grouped = ds_agg.groupby([target])\n",
    "            if len(grouped[target].unique()) < len(target_names):\n",
    "                print(f'[{name}] Not all categories represented in this dataset')\n",
    "                continue\n",
    "\n",
    "            count = grouped[target].count()\n",
    "            min_c = count.to_numpy().min()\n",
    "\n",
    "            min_cl = None\n",
    "            for target_name in target_names:\n",
    "                ds_target = ds_agg[ds_agg[target] == target_name]\n",
    "                grouped = ds_target.groupby('label', group_keys=False)\n",
    "                if len(grouped) < len(base_vocab):\n",
    "                    min_cl = 0\n",
    "                    break\n",
    "                cur_min = grouped['cropped_img'].count().min()\n",
    "                if min_cl is None or min_cl > cur_min:\n",
    "                    min_cl = cur_min\n",
    "\n",
    "            min_cl_label = {}\n",
    "            for label in vocab:\n",
    "                grouped = ds_agg[ds_agg['label'] == label].groupby([target])\n",
    "                if len(grouped[target].unique()) < len(target_names):\n",
    "                    min_cl_label[label] = 0\n",
    "                else:\n",
    "                    min_cl_label[label] = grouped['cropped_img'].count().min()\n",
    "\n",
    "\n",
    "            for target_name in target_names:\n",
    "                ds_target = ds_agg[ds_agg[target] == target_name]\n",
    "                grouped = ds_target.groupby('label', group_keys=False)\n",
    "\n",
    "                if balance == 'none':\n",
    "                    chosen = ds_target.sample(min_c)\n",
    "                elif balance == 'semi':\n",
    "                    chosen = grouped.apply(lambda x: x.sample(int(np.min((min_c / len(target_names), len(x)))), random_state=SEED))\n",
    "                elif balance == 'total':\n",
    "                    chosen = grouped.apply(lambda x: x.sample(min_cl, random_state=SEED))\n",
    "                elif balance == 'by-label':\n",
    "                    chosen = []\n",
    "                    for label in vocab:\n",
    "                        ds_target_label = ds_target[ds_target['label'] == label]\n",
    "                        chosen.append(ds_target_label.sample(min_cl_label[label], random_state=SEED))\n",
    "                    chosen = pd.concat(chosen, ignore_index=True)\n",
    "                else:\n",
    "                    raise 'Balance type not recognized'\n",
    "\n",
    "                final_ds.append(chosen)\n",
    "            \n",
    "    final_ds = pd.concat(final_ds, ignore_index=True)\n",
    "    return final_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f53de9-b82f-4d5a-85d2-0475e2d721f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'affectnet'\n",
    "\n",
    "vocab=['angry', 'contempt', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "names=[dataset]\n",
    "\n",
    "races = ['Black',\n",
    "       'East Asian',\n",
    "       'Indian',\n",
    "       'Latino_Hispanic',\n",
    "       'Middle Eastern',\n",
    "       'Southeast Asian',\n",
    "       'White']\n",
    "\n",
    "complete = generateComposedDataset(ds_names = names,\n",
    "                                   target = 'race',\n",
    "                                   target_names = races,\n",
    "                                   balance = 'by-label',\n",
    "                                   vocab = vocab\n",
    "                                  )\n",
    "display(complete)\n",
    "complete.to_csv(f'{COMPOSED_DATASETS_PATH}/compdataset_{dataset}_race_balanced.csv', index=None)\n",
    "\n",
    "\n",
    "\n",
    "complete = generateComposedDataset(ds_names = names,\n",
    "                                   target = 'gender',\n",
    "                                   target_names = ['Male', 'Female'],\n",
    "                                   balance = 'by-label',\n",
    "                                   vocab = vocab\n",
    "                                  )\n",
    "\n",
    "biased_male = generateComposedDataset(ds_names = names,\n",
    "                                   target = 'gender',\n",
    "                                   target_names = ['Male'],\n",
    "                                   balance = 'none',\n",
    "                                   vocab = vocab\n",
    "                                  )\n",
    "\n",
    "biased_female = generateComposedDataset(ds_names = names,\n",
    "                                   target = 'gender',\n",
    "                                   target_names = ['Female'],\n",
    "                                   balance = 'none',\n",
    "                                   vocab = vocab\n",
    "                                  )\n",
    "\n",
    "complete_reduced = []\n",
    "biased_male_reduced = []\n",
    "biased_female_reduced = []\n",
    "\n",
    "for partition in ['train', 'val']:\n",
    "    distribution_comp = complete[complete['partition']==partition]['label'].value_counts()\n",
    "    distribution_biased_male = biased_male[biased_male['partition']==partition]['label'].value_counts()\n",
    "    distribution_biased_female = biased_female[biased_female['partition']==partition]['label'].value_counts()\n",
    "    \n",
    "    for label in vocab:\n",
    "        n = min(distribution_comp[label], distribution_biased_male[label], distribution_biased_female[label])\n",
    "        n = n//2 *2\n",
    "        for gender in ['Male', 'Female']:\n",
    "            complete_reduced += [complete[(complete['partition'] == partition) & \n",
    "                                         (complete['label'] == label) & \n",
    "                                         (complete['gender'] == gender)].sample(n//2)]\n",
    "        biased_male_reduced += [biased_male[(biased_male['partition'] == partition) & \n",
    "                                     (biased_male['label'] == label)].sample(n)]\n",
    "        biased_female_reduced += [biased_female[(biased_female['partition'] == partition) & \n",
    "                                     (biased_female['label'] == label)].sample(n)]\n",
    "\n",
    "complete_reduced = pd.concat(complete_reduced)\n",
    "biased_male_reduced = pd.concat(biased_male_reduced)\n",
    "biased_female_reduced = pd.concat(biased_female_reduced)\n",
    "\n",
    "display(complete_reduced['label'].value_counts())\n",
    "display(biased_male_reduced['label'].value_counts())\n",
    "display(biased_female_reduced['label'].value_counts())\n",
    "\n",
    "complete_reduced.to_csv(f'{COMPOSED_DATASETS_PATH}/compdataset_{dataset}_gender_balanced.csv', index=None)\n",
    "biased_male_reduced.to_csv(f'{COMPOSED_DATASETS_PATH}/compdataset_{dataset}_gender_biased_Male-only.csv', index=None)\n",
    "biased_female_reduced.to_csv(f'{COMPOSED_DATASETS_PATH}/compdataset_{dataset}_gender_biased_Female-only.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf573348-bc6a-43e6-9ea0-5c912785a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ferplus'\n",
    "\n",
    "vocab=['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "names=[dataset]\n",
    "\n",
    "races = ['Black',\n",
    "       'East Asian',\n",
    "       'Indian',\n",
    "       'Latino_Hispanic',\n",
    "       'Middle Eastern',\n",
    "       'Southeast Asian',\n",
    "       'White']\n",
    "\n",
    "complete = generateComposedDataset(ds_names = names,\n",
    "                                   target = 'race',\n",
    "                                   target_names = races,\n",
    "                                   balance = 'by-label',\n",
    "                                   vocab = vocab\n",
    "                                  )\n",
    "display(complete)\n",
    "complete.to_csv(f'{COMPOSED_DATASETS_PATH}/compdataset_{dataset}_race_balanced.csv', index=None)\n",
    "\n",
    "\n",
    "\n",
    "complete = generateComposedDataset(ds_names = names,\n",
    "                                   target = 'gender',\n",
    "                                   target_names = ['Male', 'Female'],\n",
    "                                   balance = 'by-label',\n",
    "                                   vocab = vocab\n",
    "                                  )\n",
    "\n",
    "biased_male = generateComposedDataset(ds_names = names,\n",
    "                                   target = 'gender',\n",
    "                                   target_names = ['Male'],\n",
    "                                   balance = 'none',\n",
    "                                   vocab = vocab\n",
    "                                  )\n",
    "\n",
    "biased_female = generateComposedDataset(ds_names = names,\n",
    "                                   target = 'gender',\n",
    "                                   target_names = ['Female'],\n",
    "                                   balance = 'none',\n",
    "                                   vocab = vocab\n",
    "                                  )\n",
    "\n",
    "complete_reduced = []\n",
    "biased_male_reduced = []\n",
    "biased_female_reduced = []\n",
    "\n",
    "for partition in ['train', 'val']:\n",
    "    distribution_comp = complete[complete['partition']==partition]['label'].value_counts()\n",
    "    distribution_biased_male = biased_male[biased_male['partition']==partition]['label'].value_counts()\n",
    "    distribution_biased_female = biased_female[biased_female['partition']==partition]['label'].value_counts()\n",
    "    \n",
    "    for label in vocab:\n",
    "        n = min(distribution_comp[label], distribution_biased_male[label], distribution_biased_female[label])\n",
    "        n = n//2 *2\n",
    "        for gender in ['Male', 'Female']:\n",
    "            complete_reduced += [complete[(complete['partition'] == partition) & \n",
    "                                         (complete['label'] == label) & \n",
    "                                         (complete['gender'] == gender)].sample(n//2)]\n",
    "        biased_male_reduced += [biased_male[(biased_male['partition'] == partition) & \n",
    "                                     (biased_male['label'] == label)].sample(n)]\n",
    "        biased_female_reduced += [biased_female[(biased_female['partition'] == partition) & \n",
    "                                     (biased_female['label'] == label)].sample(n)]\n",
    "\n",
    "complete_reduced = pd.concat(complete_reduced)\n",
    "biased_male_reduced = pd.concat(biased_male_reduced)\n",
    "biased_female_reduced = pd.concat(biased_female_reduced)\n",
    "\n",
    "display(complete_reduced['label'].value_counts())\n",
    "display(biased_male_reduced['label'].value_counts())\n",
    "display(biased_female_reduced['label'].value_counts())\n",
    "\n",
    "complete_reduced.to_csv(f'{COMPOSED_DATASETS_PATH}/compdataset_{dataset}_gender_balanced.csv', index=None)\n",
    "biased_male_reduced.to_csv(f'{COMPOSED_DATASETS_PATH}/compdataset_{dataset}_gender_biased_Male-only.csv', index=None)\n",
    "biased_female_reduced.to_csv(f'{COMPOSED_DATASETS_PATH}/compdataset_{dataset}_gender_biased_Female-only.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
